{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/adding_C2/C2/W2/ungraded_labs/C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGxCD4mGHHjG"
   },
   "source": [
    "Let's start with a model that's very effective at learning Cats v Dogs.\n",
    "\n",
    "It's similar to the previous models that you have used, but I have updated the layers definition. Note that there are now 4 convolutional layers with 32, 64, 128 and 128 convolutions respectively.\n",
    "\n",
    "Also, this will train for 100 epochs, because I want to plot the graph of loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhbIJpcZdxUT"
   },
   "source": [
    "**Note:** This notebook can run using Tensorflow 2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f09kdYpdyv4"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MJPyDEzOqrKB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 18:24:13.358230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-31 18:24:14.136099: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 18:24:14.136593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-08-31 18:24:14.204990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.205511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.90GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-08-31 18:24:14.205538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-31 18:24:14.207045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-31 18:24:14.207081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-31 18:24:14.208692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-31 18:24:14.208893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-31 18:24:14.210427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-31 18:24:14.211321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-31 18:24:14.214764: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-31 18:24:14.214908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.215487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.215908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-31 18:24:14.216415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-31 18:24:14.217303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.217693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:08:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.90GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2021-08-31 18:24:14.217710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-31 18:24:14.217729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-31 18:24:14.217738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2021-08-31 18:24:14.217745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-08-31 18:24:14.217753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-08-31 18:24:14.217760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-08-31 18:24:14.217769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-08-31 18:24:14.217777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-31 18:24:14.217820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.218126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.218444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-08-31 18:24:14.218472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-08-31 18:24:14.531065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-08-31 18:24:14.531095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-08-31 18:24:14.531100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-08-31 18:24:14.531302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.531633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.531931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-08-31 18:24:14.532215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6603 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2021-08-31 18:24:14.532392: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-31 18:24:14.732399: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 18:24:14.752822: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593030000 Hz\n",
      "2021-08-31 18:24:15.147564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2021-08-31 18:24:15.242250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-08-31 18:24:15.685101: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2021-08-31 18:24:15.714864: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 11s - loss: 0.6923 - accuracy: 0.5290 - val_loss: 0.6758 - val_accuracy: 0.5390\n",
      "Epoch 2/100\n",
      "100/100 - 5s - loss: 0.6647 - accuracy: 0.6045 - val_loss: 0.6327 - val_accuracy: 0.6650\n",
      "Epoch 3/100\n",
      "100/100 - 5s - loss: 0.6208 - accuracy: 0.6520 - val_loss: 0.6169 - val_accuracy: 0.6540\n",
      "Epoch 4/100\n",
      "100/100 - 5s - loss: 0.5812 - accuracy: 0.6980 - val_loss: 0.5904 - val_accuracy: 0.6860\n",
      "Epoch 5/100\n",
      "100/100 - 5s - loss: 0.5470 - accuracy: 0.7315 - val_loss: 0.5913 - val_accuracy: 0.6860\n",
      "Epoch 6/100\n",
      "100/100 - 5s - loss: 0.5118 - accuracy: 0.7525 - val_loss: 0.5690 - val_accuracy: 0.6960\n",
      "Epoch 7/100\n",
      "100/100 - 5s - loss: 0.4830 - accuracy: 0.7615 - val_loss: 0.5895 - val_accuracy: 0.7020\n",
      "Epoch 8/100\n",
      "100/100 - 5s - loss: 0.4535 - accuracy: 0.7825 - val_loss: 0.5505 - val_accuracy: 0.7190\n",
      "Epoch 9/100\n",
      "100/100 - 5s - loss: 0.4261 - accuracy: 0.7925 - val_loss: 0.5501 - val_accuracy: 0.7350\n",
      "Epoch 10/100\n",
      "100/100 - 5s - loss: 0.3983 - accuracy: 0.8165 - val_loss: 0.5765 - val_accuracy: 0.7170\n",
      "Epoch 11/100\n",
      "100/100 - 5s - loss: 0.3718 - accuracy: 0.8335 - val_loss: 0.5394 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "100/100 - 5s - loss: 0.3511 - accuracy: 0.8415 - val_loss: 0.5439 - val_accuracy: 0.7490\n",
      "Epoch 13/100\n",
      "100/100 - 5s - loss: 0.3219 - accuracy: 0.8675 - val_loss: 0.5378 - val_accuracy: 0.7590\n",
      "Epoch 14/100\n",
      "100/100 - 5s - loss: 0.3074 - accuracy: 0.8675 - val_loss: 0.5894 - val_accuracy: 0.7190\n",
      "Epoch 15/100\n",
      "100/100 - 5s - loss: 0.2737 - accuracy: 0.8915 - val_loss: 0.5976 - val_accuracy: 0.7430\n",
      "Epoch 16/100\n",
      "100/100 - 5s - loss: 0.2483 - accuracy: 0.9020 - val_loss: 0.7073 - val_accuracy: 0.6950\n",
      "Epoch 17/100\n",
      "100/100 - 5s - loss: 0.2275 - accuracy: 0.9130 - val_loss: 0.5579 - val_accuracy: 0.7470\n",
      "Epoch 18/100\n",
      "100/100 - 5s - loss: 0.2020 - accuracy: 0.9220 - val_loss: 0.6049 - val_accuracy: 0.7490\n",
      "Epoch 19/100\n",
      "100/100 - 5s - loss: 0.1918 - accuracy: 0.9285 - val_loss: 0.6337 - val_accuracy: 0.7350\n",
      "Epoch 20/100\n",
      "100/100 - 5s - loss: 0.1537 - accuracy: 0.9475 - val_loss: 0.6107 - val_accuracy: 0.7490\n",
      "Epoch 21/100\n",
      "100/100 - 5s - loss: 0.1359 - accuracy: 0.9550 - val_loss: 0.6510 - val_accuracy: 0.7580\n",
      "Epoch 22/100\n",
      "100/100 - 5s - loss: 0.1249 - accuracy: 0.9580 - val_loss: 0.6895 - val_accuracy: 0.7440\n",
      "Epoch 23/100\n",
      "100/100 - 5s - loss: 0.1096 - accuracy: 0.9660 - val_loss: 0.7412 - val_accuracy: 0.7390\n",
      "Epoch 24/100\n",
      "100/100 - 5s - loss: 0.0829 - accuracy: 0.9790 - val_loss: 0.8329 - val_accuracy: 0.7460\n",
      "Epoch 25/100\n",
      "100/100 - 5s - loss: 0.0766 - accuracy: 0.9765 - val_loss: 0.7889 - val_accuracy: 0.7480\n",
      "Epoch 26/100\n",
      "100/100 - 5s - loss: 0.0645 - accuracy: 0.9815 - val_loss: 0.7769 - val_accuracy: 0.7460\n",
      "Epoch 27/100\n",
      "100/100 - 5s - loss: 0.0569 - accuracy: 0.9840 - val_loss: 0.8009 - val_accuracy: 0.7490\n",
      "Epoch 28/100\n",
      "100/100 - 5s - loss: 0.0421 - accuracy: 0.9910 - val_loss: 0.8664 - val_accuracy: 0.7570\n",
      "Epoch 29/100\n",
      "100/100 - 5s - loss: 0.0468 - accuracy: 0.9870 - val_loss: 0.8314 - val_accuracy: 0.7590\n",
      "Epoch 30/100\n",
      "100/100 - 5s - loss: 0.0356 - accuracy: 0.9905 - val_loss: 0.8809 - val_accuracy: 0.7650\n",
      "Epoch 31/100\n",
      "100/100 - 5s - loss: 0.0254 - accuracy: 0.9945 - val_loss: 1.0265 - val_accuracy: 0.7540\n",
      "Epoch 32/100\n",
      "100/100 - 5s - loss: 0.0292 - accuracy: 0.9945 - val_loss: 1.1447 - val_accuracy: 0.7220\n",
      "Epoch 33/100\n",
      "100/100 - 5s - loss: 0.0167 - accuracy: 0.9955 - val_loss: 1.0932 - val_accuracy: 0.7570\n",
      "Epoch 34/100\n",
      "100/100 - 5s - loss: 0.0217 - accuracy: 0.9970 - val_loss: 1.1198 - val_accuracy: 0.7630\n",
      "Epoch 35/100\n",
      "100/100 - 5s - loss: 0.0160 - accuracy: 0.9955 - val_loss: 1.0695 - val_accuracy: 0.7620\n",
      "Epoch 36/100\n",
      "100/100 - 5s - loss: 0.0206 - accuracy: 0.9935 - val_loss: 1.1145 - val_accuracy: 0.7570\n",
      "Epoch 37/100\n",
      "100/100 - 5s - loss: 0.0117 - accuracy: 0.9975 - val_loss: 1.2113 - val_accuracy: 0.7610\n",
      "Epoch 38/100\n",
      "100/100 - 5s - loss: 0.0112 - accuracy: 0.9975 - val_loss: 1.1895 - val_accuracy: 0.7690\n",
      "Epoch 39/100\n",
      "100/100 - 5s - loss: 0.0147 - accuracy: 0.9970 - val_loss: 1.2482 - val_accuracy: 0.7560\n",
      "Epoch 40/100\n",
      "100/100 - 5s - loss: 0.0165 - accuracy: 0.9955 - val_loss: 1.2966 - val_accuracy: 0.7450\n",
      "Epoch 41/100\n",
      "100/100 - 5s - loss: 0.0097 - accuracy: 0.9965 - val_loss: 1.3267 - val_accuracy: 0.7710\n",
      "Epoch 42/100\n",
      "100/100 - 5s - loss: 0.0090 - accuracy: 0.9975 - val_loss: 1.2820 - val_accuracy: 0.7700\n",
      "Epoch 43/100\n",
      "100/100 - 5s - loss: 0.0044 - accuracy: 0.9975 - val_loss: 1.3385 - val_accuracy: 0.7630\n",
      "Epoch 44/100\n",
      "100/100 - 6s - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.3834 - val_accuracy: 0.7510\n",
      "Epoch 45/100\n",
      "100/100 - 5s - loss: 0.0038 - accuracy: 0.9995 - val_loss: 1.3730 - val_accuracy: 0.7530\n",
      "Epoch 46/100\n",
      "100/100 - 5s - loss: 0.0048 - accuracy: 0.9980 - val_loss: 1.7785 - val_accuracy: 0.7230\n",
      "Epoch 47/100\n",
      "100/100 - 5s - loss: 0.0173 - accuracy: 0.9950 - val_loss: 1.3630 - val_accuracy: 0.7650\n",
      "Epoch 48/100\n",
      "100/100 - 5s - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.4149 - val_accuracy: 0.7690\n",
      "Epoch 49/100\n",
      "100/100 - 5s - loss: 0.0031 - accuracy: 0.9990 - val_loss: 1.5438 - val_accuracy: 0.7560\n",
      "Epoch 50/100\n",
      "100/100 - 5s - loss: 0.0191 - accuracy: 0.9940 - val_loss: 1.5722 - val_accuracy: 0.7520\n",
      "Epoch 51/100\n",
      "100/100 - 5s - loss: 0.0103 - accuracy: 0.9965 - val_loss: 1.4802 - val_accuracy: 0.7560\n",
      "Epoch 52/100\n",
      "100/100 - 5s - loss: 0.0115 - accuracy: 0.9965 - val_loss: 2.3121 - val_accuracy: 0.6940\n",
      "Epoch 53/100\n",
      "100/100 - 5s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.7590\n",
      "Epoch 54/100\n",
      "100/100 - 5s - loss: 0.0068 - accuracy: 0.9955 - val_loss: 1.6449 - val_accuracy: 0.7570\n",
      "Epoch 55/100\n",
      "100/100 - 5s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.6158 - val_accuracy: 0.7540\n",
      "Epoch 56/100\n",
      "100/100 - 5s - loss: 0.0066 - accuracy: 0.9990 - val_loss: 1.7331 - val_accuracy: 0.7540\n",
      "Epoch 57/100\n",
      "100/100 - 5s - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.7894 - val_accuracy: 0.7510\n",
      "Epoch 58/100\n",
      "100/100 - 5s - loss: 4.6876e-04 - accuracy: 1.0000 - val_loss: 1.7706 - val_accuracy: 0.7570\n",
      "Epoch 59/100\n",
      "100/100 - 5s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5050 - val_accuracy: 0.7120\n",
      "Epoch 60/100\n",
      "100/100 - 5s - loss: 0.0137 - accuracy: 0.9970 - val_loss: 1.8143 - val_accuracy: 0.7610\n",
      "Epoch 61/100\n",
      "100/100 - 5s - loss: 0.0100 - accuracy: 0.9990 - val_loss: 1.7669 - val_accuracy: 0.7630\n",
      "Epoch 62/100\n",
      "100/100 - 5s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.8936 - val_accuracy: 0.7530\n",
      "Epoch 63/100\n",
      "100/100 - 5s - loss: 0.0081 - accuracy: 0.9970 - val_loss: 1.7452 - val_accuracy: 0.7470\n",
      "Epoch 64/100\n",
      "100/100 - 5s - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.7180 - val_accuracy: 0.7540\n",
      "Epoch 65/100\n",
      "100/100 - 5s - loss: 0.0068 - accuracy: 0.9985 - val_loss: 1.8226 - val_accuracy: 0.7530\n",
      "Epoch 66/100\n",
      "100/100 - 5s - loss: 0.0035 - accuracy: 0.9990 - val_loss: 1.8863 - val_accuracy: 0.7400\n",
      "Epoch 67/100\n",
      "100/100 - 5s - loss: 0.0113 - accuracy: 0.9965 - val_loss: 1.8364 - val_accuracy: 0.7540\n",
      "Epoch 68/100\n",
      "100/100 - 5s - loss: 0.0074 - accuracy: 0.9980 - val_loss: 1.9611 - val_accuracy: 0.7530\n",
      "Epoch 69/100\n",
      "100/100 - 5s - loss: 5.9217e-05 - accuracy: 1.0000 - val_loss: 2.0315 - val_accuracy: 0.7570\n",
      "Epoch 70/100\n",
      "100/100 - 5s - loss: 0.0109 - accuracy: 0.9975 - val_loss: 1.9564 - val_accuracy: 0.7600\n",
      "Epoch 71/100\n",
      "100/100 - 5s - loss: 0.0053 - accuracy: 0.9990 - val_loss: 1.9569 - val_accuracy: 0.7520\n",
      "Epoch 72/100\n",
      "100/100 - 5s - loss: 0.0048 - accuracy: 0.9975 - val_loss: 1.9967 - val_accuracy: 0.7570\n",
      "Epoch 73/100\n",
      "100/100 - 5s - loss: 0.0124 - accuracy: 0.9975 - val_loss: 2.0340 - val_accuracy: 0.7580\n",
      "Epoch 74/100\n",
      "100/100 - 5s - loss: 0.0021 - accuracy: 0.9990 - val_loss: 2.4593 - val_accuracy: 0.7220\n",
      "Epoch 75/100\n",
      "100/100 - 5s - loss: 0.0077 - accuracy: 0.9970 - val_loss: 1.9783 - val_accuracy: 0.7550\n",
      "Epoch 76/100\n",
      "100/100 - 5s - loss: 0.0025 - accuracy: 0.9985 - val_loss: 2.0233 - val_accuracy: 0.7490\n",
      "Epoch 77/100\n",
      "100/100 - 5s - loss: 0.0027 - accuracy: 0.9985 - val_loss: 2.0495 - val_accuracy: 0.7520\n",
      "Epoch 78/100\n",
      "100/100 - 5s - loss: 0.0110 - accuracy: 0.9985 - val_loss: 2.1133 - val_accuracy: 0.7550\n",
      "Epoch 79/100\n",
      "100/100 - 5s - loss: 0.0040 - accuracy: 0.9990 - val_loss: 1.9886 - val_accuracy: 0.7490\n",
      "Epoch 80/100\n",
      "100/100 - 5s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 2.1244 - val_accuracy: 0.7550\n",
      "Epoch 81/100\n",
      "100/100 - 5s - loss: 0.0061 - accuracy: 0.9990 - val_loss: 2.1394 - val_accuracy: 0.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "100/100 - 5s - loss: 0.0047 - accuracy: 0.9990 - val_loss: 2.0961 - val_accuracy: 0.7400\n",
      "Epoch 83/100\n",
      "100/100 - 5s - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.1783 - val_accuracy: 0.7460\n",
      "Epoch 84/100\n",
      "100/100 - 5s - loss: 0.0025 - accuracy: 0.9990 - val_loss: 2.2757 - val_accuracy: 0.7330\n",
      "Epoch 85/100\n",
      "100/100 - 5s - loss: 3.8978e-05 - accuracy: 1.0000 - val_loss: 2.1621 - val_accuracy: 0.7480\n",
      "Epoch 86/100\n",
      "100/100 - 5s - loss: 0.0066 - accuracy: 0.9985 - val_loss: 2.1752 - val_accuracy: 0.7430\n",
      "Epoch 87/100\n",
      "100/100 - 5s - loss: 0.0023 - accuracy: 0.9990 - val_loss: 2.4738 - val_accuracy: 0.7210\n",
      "Epoch 88/100\n",
      "100/100 - 5s - loss: 5.0973e-05 - accuracy: 1.0000 - val_loss: 2.2703 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "100/100 - 5s - loss: 0.0018 - accuracy: 0.9995 - val_loss: 2.2636 - val_accuracy: 0.7580\n",
      "Epoch 90/100\n",
      "100/100 - 5s - loss: 0.0080 - accuracy: 0.9990 - val_loss: 2.3492 - val_accuracy: 0.7450\n",
      "Epoch 91/100\n",
      "100/100 - 5s - loss: 4.6028e-04 - accuracy: 1.0000 - val_loss: 2.2465 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "100/100 - 5s - loss: 0.0019 - accuracy: 0.9995 - val_loss: 2.3796 - val_accuracy: 0.7450\n",
      "Epoch 93/100\n",
      "100/100 - 5s - loss: 0.0030 - accuracy: 0.9990 - val_loss: 2.3445 - val_accuracy: 0.7550\n",
      "Epoch 94/100\n",
      "100/100 - 5s - loss: 2.6926e-05 - accuracy: 1.0000 - val_loss: 2.4329 - val_accuracy: 0.7540\n",
      "Epoch 95/100\n",
      "100/100 - 5s - loss: 0.0108 - accuracy: 0.9975 - val_loss: 2.4274 - val_accuracy: 0.7470\n",
      "Epoch 96/100\n",
      "100/100 - 5s - loss: 1.1125e-05 - accuracy: 1.0000 - val_loss: 2.4275 - val_accuracy: 0.7540\n",
      "Epoch 97/100\n",
      "100/100 - 5s - loss: 0.0098 - accuracy: 0.9975 - val_loss: 2.3334 - val_accuracy: 0.7510\n",
      "Epoch 98/100\n",
      "100/100 - 5s - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.3973 - val_accuracy: 0.7460\n",
      "Epoch 99/100\n",
      "100/100 - 5s - loss: 1.5162e-05 - accuracy: 1.0000 - val_loss: 2.3803 - val_accuracy: 0.7580\n",
      "Epoch 100/100\n",
      "100/100 - 5s - loss: 0.0073 - accuracy: 0.9970 - val_loss: 2.4959 - val_accuracy: 0.7470\n"
     ]
    }
   ],
   "source": [
    "#!gdown --id 1RL0T7Rg4XqQNRCkjfnLo4goOJQ7XZro9\n",
    "  \n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "#zip_ref.extractall(\"tmp/\")\n",
    "#zip_ref.close()\n",
    "\n",
    "base_dir = '/home/philipp/Code/python/csa_tensorflow/C2/data/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZWPcmKWO303"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb81GvNov-Tg"
   },
   "source": [
    "The Training Accuracy is close to 100%, and the validation accuracy is in the 70%-80% range. This is a great example of overfitting -- which in short means that it can do very well with images it has seen before, but not so well with images it hasn't. Let's see if we can do better to avoid overfitting -- and one simple method is to augment the images a bit. If you think about it, most pictures of a cat are very similar -- the ears are at the top, then the eyes, then the mouth etc. Things like the distance between the eyes and ears will always be quite similar too. \n",
    "\n",
    "What if we tweak with the images to change this up a bit -- rotate the image, squash it, etc.  That's what image augementation is all about. And there's an API that makes it easy...\n",
    "\n",
    "Now take a look at the ImageGenerator. There are properties on it that you can use to augment the image. \n",
    "\n",
    "```\n",
    "# Updated to do image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "```\n",
    "These are just a few of the options available (for more, see the Keras documentation. Let's quickly go over what we just wrote:\n",
    "\n",
    "* rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.\n",
    "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
    "* shear_range is for randomly applying shearing transformations.\n",
    "* zoom_range is for randomly zooming inside pictures.\n",
    "* horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).\n",
    "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "\n",
    "\n",
    "Here's some code where we've added Image Augmentation. Run it to see the impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK7_Fflgv8YC"
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1RL0T7Rg4XqQNRCkjfnLo4goOJQ7XZro9\n",
    "\n",
    "  \n",
    "# import os\n",
    "# import zipfile\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "# zip_ref.extractall(\"tmp/\")\n",
    "# zip_ref.close()\n",
    "\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
    "# the image, we also rotate and do other operations\n",
    "# Updated to do image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnyRnwopT5aW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmYgnrcobqw1"
   },
   "outputs": [],
   "source": [
    "# !gdown --id 1RL0T7Rg4XqQNRCkjfnLo4goOJQ7XZro9\n",
    "\n",
    "  \n",
    "# import os\n",
    "# import zipfile\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# zip_ref = zipfile.ZipFile(\"./cats_and_dogs_filtered.zip\", 'r')\n",
    "# zip_ref.extractall(\"tmp/\")\n",
    "# zip_ref.close()\n",
    "\n",
    "base_dir = 'tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
    "# the image, we also rotate and do other operations\n",
    "# Updated to do image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3yFv2Jpb2Dl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
